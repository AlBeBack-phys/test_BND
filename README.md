# Детекция людей с использованием Mask R-CNN

Этот проект реализует трекинг и сегментацию объектов с использованием предобученной модели Mask R-CNN из библиотеки `torchvision`. Скрипт обрабатывает видео для детекции и трекинга людей назначая каждому обнаруженному человеку уникальный случайный цвет, который сохраняется на протяжении всего видео.

На выходе создается видео, где люди выделены цветными масками, а также отображаются их классы и уверенность модели. Программа автоматически использует GPU, если оно доступно.

## Как это работает

1. **Детекция объектов с Mask R-CNN**: Модель использует предобученную Mask R-CNN(MaskRCNN_ResNet50_FPN) для детекции и сегментации людей на каждом кадре видео. 

2. **Трекинг объектов**: Класс `ObjectTracker` отвечает за отслеживание обнаруженных объектов между кадрами. Он сравнивает ограничивающие рамки из текущего кадра с рамками из предыдущего кадра, используя метрику IoU(intersection-over-union). Если найдено совпадение, объект сохраняет свой цвет с предыдущего кадра, иначе ему назначается новый случайный цвет.

3. **Наложение маски**: Для каждого обнаруженного человека на изображение накладывается маска с прозрачностью alpha(можно регулировать самостоятельно).

4. **Сохранение результата**: После обработки видео скрипт сохраняет результат в новый видеофайл, на котором люди выделены цветными масками.

## Использование

Установите все пакеты из requirements.txt. Затем выполните код из файла inference_model.py
Вам будет предложено казать путь к самому видео, а также выходной путь - куда будет загружено видео, полученное в результате работы программы

Пример:

```
Введите путь к видео: /path/to/input/video.mp4
Укажите путь для сохранения результата: /path/to/output/result.mp4
```

## Дополнительные параметры

По умолчанию скрипт обрабатывает кадры видео батчами для ускорения вычислений на GPU. Вы можете изменить размер батча, порог уверенности и прозрачность маски, изменив параметры функции `segment_people()`:

- `batch_size` (по умолчанию: 5): Количество кадров для параллельной обработки. Большие батчи ускоряют обработку при наличии мощного GPU.
- `threshold` (по умолчанию: 0.3): Порог уверенности. Предсказания с уверенностью ниже этого значения будут игнорироваться.
- `mask_alpha` (по умолчанию: 0.6): Прозрачность наложенной маски.

Пример работы программы можно найти в файле `result.mp4` в [папке на диске](https://disk.yandex.ru/d/D8-jHsDDm7nevw).
Исходное видео там же - `crowd.mp4`

## Пути для улучшения полученного результата:
   
   - Если мы реализовываем детекцию для конкретных камер и ракурсов, можно с помощью идеи transfer learning дообучить модель на данные с наших камер. Это поможет модели лучше подстраиваться под геометрию нашей местности;
   - Улучшить текущий или разработать другой алгоритм трекинга объекта. Например, можно использовать идентификацию объекта на основе внешних характеристик: цвет одежды, цвет кожи и т.п., чтобы мы имели возможность отследить данный объект даже если он на несколько кадров пропал из нашей зоны видимости(например, зашёл за какое-то препятствие);
   - Можно обучить(или использовать готовую) модель для улучшения качества кадров, это может заметно улучшить результат работы модели сегментации в случае если качество видео с камер оставляет желать лучшего
   - Если для нас важна скорость обработки видео(например, мы хотим реализовать life-time систему), можно воспользоваться более быстрыми архитектурами для сегментации, например, YOLO. Напротив, если мы можем позволить себе обрабатывать видео подолгу, можем взять ещё более медленную, но вместе с тем более глубокую и точную модель(например, MaskRCNN_ResNet101_FPN)
   - Более тщательно настроить параметр threshold в зависимости от задачи. Если для нас важнее полнота предсказаний(хотим захватить как можно больше таргетных объектов, при этом некритично если возьмём что-то лишнее), тогда параметр threshold следует установить ниже, если для нас важнее точность предсказаний, нужно установить этот параметр выше.
